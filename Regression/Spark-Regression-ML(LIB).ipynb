{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task :- Use of  Machine Learning Library (MLlib) :- Spark’s machine learning (ML) library for Regression\n",
    "### Models :- Linear Regression, Decision Tree Regression,Random forest regression,Gradient-boosted tree regression.\n",
    "### Dataset :- insurance.csv.\n",
    "\n",
    "**MLlib is Spark’s machine learning (ML) library. Its goal is to make practical machine learning scalable and easy. At a high level, it provides tools such as:**\n",
    "\n",
    "<ul>\n",
    "<li> ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering.</li>\n",
    "\n",
    "<li> Featurization: feature extraction, transformation, dimensionality reduction, and selection.</li>\n",
    "\n",
    "<li> Pipelines: tools for constructing, evaluating, and tuning ML Pipelines.</li>\n",
    "\n",
    "<li> Persistence: saving and load algorithms, models, and Pipelines.</li>\n",
    "\n",
    "<li> Utilities: linear algebra, statistics, data handling, etc.</li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20200303101851-0000\n",
      "KERNEL_ID = 2ce083b6-bf23-4ab9-b3a4-d98a882a55d0\n"
     ]
    }
   ],
   "source": [
    "# For Local Machine sparkcontext creation\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# In cloud the sparkcontext is created as \"sc\" \n",
    "# ex:- IBM watson \n",
    "# python :- 3.6\n",
    "# spark :- 2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# IBM WATSON PYTHON+SPARK ENVIRONMENT\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'XXXX',\n",
    "    'service_id': 'XXXX',\n",
    "    'iam_service_endpoint': 'XXXX',\n",
    "    'api_key': 'XXXX'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_0a7faf2d576d4d0e985305b42aae4ce7_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'IAM_SERVICE_ID': 'XXXX',\n",
    "    'IBM_API_KEY_ID': 'XXXX',\n",
    "    'ENDPOINT': 'XXXX',\n",
    "    'IBM_AUTH_ENDPOINT': 'XXXX',\n",
    "    'BUCKET': 'XXXX',\n",
    "    'FILE': 'insurance.csv'\n",
    "}\n",
    "data_link = cos.url('insurance.csv', 'sparktry-donotdelete-pr-adbnjs9sf1yuav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insurence = spark.read.csv(data_link, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insurence.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_insurence.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- charges: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_insurence.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+------------------+-----------------+------+---------+------------------+\n",
      "|summary|               age|   sex|               bmi|         children|smoker|   region|           charges|\n",
      "+-------+------------------+------+------------------+-----------------+------+---------+------------------+\n",
      "|  count|              1338|  1338|              1338|             1338|  1338|     1338|              1338|\n",
      "|   mean| 39.20702541106129|  null|30.663396860986538|  1.0949177877429|  null|     null|13270.422265141257|\n",
      "| stddev|14.049960379216147|  null| 6.098186911679012|1.205492739781914|  null|     null|12110.011236693992|\n",
      "|    min|                18|female|             15.96|                0|    no|northeast|         1121.8739|\n",
      "|    max|                64|  male|             53.13|                5|   yes|southwest|       63770.42801|\n",
      "+-------+------------------+------+------------------+-----------------+------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_insurence.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sex columns \n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"smoker\", outputCol=\"smokerIndex\")\n",
    "df_insurence = indexer.fit(df_insurence).transform(df_insurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"sex\", outputCol=\"sexIndex\")\n",
    "df_insurence = indexer.fit(df_insurence).transform(df_insurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+-----------+--------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|smokerIndex|sexIndex|\n",
      "+---+------+------+--------+------+---------+-----------+-----------+--------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|        1.0|     1.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|        0.0|     0.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|        0.0|     0.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|        0.0|     0.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|        0.0|     0.0|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|        0.0|     1.0|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|        0.0|     1.0|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|        0.0|     1.0|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|        0.0|     0.0|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|        0.0|     1.0|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|        0.0|     0.0|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|        1.0|     1.0|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|        0.0|     0.0|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|        0.0|     1.0|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|        1.0|     0.0|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|        0.0|     0.0|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|        0.0|     1.0|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|        0.0|     0.0|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|        0.0|     0.0|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|        1.0|     0.0|\n",
      "+---+------+------+--------+------+---------+-----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_insurence.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+-----------+--------+-------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|smokerIndex|sexIndex| children_enc|\n",
      "+---+------+------+--------+------+---------+-----------+-----------+--------+-------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|        1.0|     1.0|(5,[0],[1.0])|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|        0.0|     0.0|(5,[1],[1.0])|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|        0.0|     0.0|(5,[3],[1.0])|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|        0.0|     0.0|(5,[0],[1.0])|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|        0.0|     0.0|(5,[0],[1.0])|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|        0.0|     1.0|(5,[0],[1.0])|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|        0.0|     1.0|(5,[1],[1.0])|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|        0.0|     1.0|(5,[3],[1.0])|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|        0.0|     0.0|(5,[2],[1.0])|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|        0.0|     1.0|(5,[0],[1.0])|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|        0.0|     0.0|(5,[0],[1.0])|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|        1.0|     1.0|(5,[0],[1.0])|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|        0.0|     0.0|(5,[0],[1.0])|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|        0.0|     1.0|(5,[0],[1.0])|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|        1.0|     0.0|(5,[0],[1.0])|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|        0.0|     0.0|(5,[1],[1.0])|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|        0.0|     1.0|(5,[1],[1.0])|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|        0.0|     0.0|(5,[0],[1.0])|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|        0.0|     0.0|(5,[0],[1.0])|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|        1.0|     0.0|(5,[0],[1.0])|\n",
      "+---+------+------+--------+------+---------+-----------+-----------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"children\"],outputCols=[\"children_enc\"])\n",
    "model = encoder.fit(df_insurence)\n",
    "encoded = model.transform(df_insurence)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+-----------+--------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|smokerIndex|sexIndex|\n",
      "+---+------+------+--------+------+---------+-----------+-----------+--------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|        1.0|     1.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|        0.0|     0.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|        0.0|     0.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|        0.0|     0.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|        0.0|     0.0|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|        0.0|     1.0|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|        0.0|     1.0|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|        0.0|     1.0|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|        0.0|     0.0|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|        0.0|     1.0|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|        0.0|     0.0|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|        1.0|     1.0|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|        0.0|     0.0|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|        0.0|     1.0|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|        1.0|     0.0|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|        0.0|     0.0|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|        0.0|     1.0|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|        0.0|     0.0|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|        0.0|     0.0|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|        1.0|     0.0|\n",
      "+---+------+------+--------+------+---------+-----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_insurence.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_insurence.drop(\"sex\", \"smoker\",'region') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+-----------+-----------+--------+\n",
      "|age|   bmi|children|    charges|smokerIndex|sexIndex|\n",
      "+---+------+--------+-----------+-----------+--------+\n",
      "| 19|  27.9|       0|  16884.924|        1.0|     1.0|\n",
      "| 18| 33.77|       1|  1725.5523|        0.0|     0.0|\n",
      "| 28|  33.0|       3|   4449.462|        0.0|     0.0|\n",
      "| 33|22.705|       0|21984.47061|        0.0|     0.0|\n",
      "| 32| 28.88|       0|  3866.8552|        0.0|     0.0|\n",
      "| 31| 25.74|       0|  3756.6216|        0.0|     1.0|\n",
      "| 46| 33.44|       1|  8240.5896|        0.0|     1.0|\n",
      "| 37| 27.74|       3|  7281.5056|        0.0|     1.0|\n",
      "| 37| 29.83|       2|  6406.4107|        0.0|     0.0|\n",
      "| 60| 25.84|       0|28923.13692|        0.0|     1.0|\n",
      "+---+------+--------+-----------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['age','bmi','smokerIndex','sexIndex'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = vectorAssembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = vec_df.select(['features', 'charges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|    charges|\n",
      "+--------------------+-----------+\n",
      "| [19.0,27.9,1.0,1.0]|  16884.924|\n",
      "|[18.0,33.77,0.0,0.0]|  1725.5523|\n",
      "| [28.0,33.0,0.0,0.0]|   4449.462|\n",
      "|[33.0,22.705,0.0,...|21984.47061|\n",
      "|[32.0,28.88,0.0,0.0]|  3866.8552|\n",
      "|[31.0,25.74,0.0,1.0]|  3756.6216|\n",
      "|[46.0,33.44,0.0,1.0]|  8240.5896|\n",
      "|[37.0,27.74,0.0,1.0]|  7281.5056|\n",
      "|[37.0,29.83,0.0,0.0]|  6406.4107|\n",
      "|[60.0,25.84,0.0,1.0]|28923.13692|\n",
      "+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vec_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|    charges|\n",
      "+--------------------+-----------+\n",
      "|[18.0,15.96,0.0,0.0]|  1694.7964|\n",
      "|[18.0,17.29,1.0,0.0]| 12829.4551|\n",
      "|[18.0,20.79,0.0,1.0]|  1607.5101|\n",
      "|[18.0,21.47,0.0,0.0]|  1702.4553|\n",
      "|[18.0,21.565,1.0,...|13747.87235|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|   charges|\n",
      "+--------------------+----------+\n",
      "|[18.0,21.66,1.0,1.0]|14283.4594|\n",
      "|[18.0,22.99,0.0,0.0]| 1704.5681|\n",
      "|[18.0,23.32,0.0,0.0]| 1711.0268|\n",
      "|[18.0,25.08,0.0,1.0]| 2196.4732|\n",
      "|[18.0,26.315,0.0,...|2198.18985|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "# creating object\n",
    "lr_model = LinearRegression(featuresCol = 'features', labelCol='charges',maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting of lr_model\n",
    "lr_fit_model = lr_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [271.6507931145969,322.39065982243727,24047.291135294545,269.953461340607]\n",
      "Intercept: -12271.26211988909\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linear regression\n",
    "\n",
    "print(\"Coefficients: %s\" % str(lr_fit_model.coefficients))\n",
    "print(\"Intercept: %s\" % str(lr_fit_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lr_fit_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 10\n",
      "objectiveHistory: [0.4999999999999998, 0.413297188039175, 0.19470668817238454, 0.14013220654793987, 0.12200415453921501, 0.12194420502663178, 0.12194366377518097, 0.12194365977107377, 0.12194365973062525, 0.12194365973048024]\n",
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "| 3930.989313060246|\n",
      "|-9410.422699798139|\n",
      "|2016.6026647772692|\n",
      "|2162.2756774386185|\n",
      "| -9870.22552053906|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summerizing the model\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6041.171187\n",
      "r2: 0.756166\n"
     ]
    }
   ],
   "source": [
    "# model  summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------+\n",
      "|        prediction|   charges|            features|\n",
      "+------------------+----------+--------------------+\n",
      "|  23918.6784445628|14283.4594|[18.0,21.66,1.0,1.0]|\n",
      "|30.213425491487214| 1704.5681|[18.0,22.99,0.0,0.0]|\n",
      "|136.60234323289296| 1711.0268|[18.0,23.32,0.0,0.0]|\n",
      "| 973.9633658609873| 2196.4732|[18.0,25.08,0.0,1.0]|\n",
      "| 1372.115830741699|2198.18985|[18.0,26.315,0.0,...|\n",
      "+------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_predictions = lr_fit_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"charges\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 6192.31\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(lr_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object creation \n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(featuresCol ='features', labelCol = 'charges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the decision tree model\n",
    "dt_model = dt_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------+\n",
      "|        prediction|   charges|            features|\n",
      "+------------------+----------+--------------------+\n",
      "|13473.944483333333|14283.4594|[18.0,21.66,1.0,1.0]|\n",
      "| 2438.034821463415| 1704.5681|[18.0,22.99,0.0,0.0]|\n",
      "| 2438.034821463415| 1711.0268|[18.0,23.32,0.0,0.0]|\n",
      "| 2438.034821463415| 2196.4732|[18.0,25.08,0.0,1.0]|\n",
      "| 2438.034821463415|2198.18985|[18.0,26.315,0.0,...|\n",
      "+------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the value\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select(\"prediction\",\"charges\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4779.97\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(featuresCol=\"features\",labelCol = 'charges',maxDepth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model_fit = rf_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------+\n",
      "|        prediction|   charges|            features|\n",
      "+------------------+----------+--------------------+\n",
      "|16943.409422856552|14283.4594|[18.0,21.66,1.0,1.0]|\n",
      "|3897.5943326143934| 1704.5681|[18.0,22.99,0.0,0.0]|\n",
      "|3897.5943326143934| 1711.0268|[18.0,23.32,0.0,0.0]|\n",
      "| 4208.915798432345| 2196.4732|[18.0,25.08,0.0,1.0]|\n",
      "| 4208.915798432345|2198.18985|[18.0,26.315,0.0,...|\n",
      "+------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting the value\n",
    "rf_predictions = rf_model_fit.transform(test_df)\n",
    "rf_predictions.select('prediction', 'charges', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4728.05\n",
      "R2 on test data = 0.83937\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "rf_evaluator = RegressionEvaluator(labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = rf_evaluator.evaluate(rf_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rf_evaluator1 = RegressionEvaluator(labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = rf_evaluator1.evaluate(rf_predictions)\n",
    "print(\"R2 on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-boosted Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object creation\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt_model = GBTRegressor(featuresCol = 'features', labelCol = 'charges',maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "gbt_model_fit = gbt_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------+\n",
      "|        prediction|   charges|            features|\n",
      "+------------------+----------+--------------------+\n",
      "| 13767.94453120202|14283.4594|[18.0,21.66,1.0,1.0]|\n",
      "|  2423.42353356794| 1704.5681|[18.0,22.99,0.0,0.0]|\n",
      "|  2423.42353356794| 1711.0268|[18.0,23.32,0.0,0.0]|\n",
      "|2574.6189193968994| 2196.4732|[18.0,25.08,0.0,1.0]|\n",
      "|  3070.10056951776|2198.18985|[18.0,26.315,0.0,...|\n",
      "+------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting the value\n",
    "gbt_predictions = gbt_model_fit.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'charges', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4929.58\n",
      "R2 on test data = 0.825385\n"
     ]
    }
   ],
   "source": [
    "# evaluating \n",
    "gbt_evaluator = RegressionEvaluator(labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "gbt_evaluator1 = RegressionEvaluator(labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = gbt_evaluator1.evaluate(gbt_predictions)\n",
    "print(\"R2 on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ** Thanks! ** </center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
